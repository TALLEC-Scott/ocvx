{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP I : Descentes de Gradient\n",
    "\n",
    "Ce TP vise à apporter les éléments nécessaires pour comprendre les implementations des descentes de gradients. **C'est un *TP à trous* ; il s'agira de compléter ces trous et d'y ajouter les tests qui vous sembleront utiles.**\n",
    "\n",
    "Voici un aperçu des points abordés lors de ce TP.\n",
    "\n",
    "- partie I\n",
    "    - Définition d'un ensemble de fonctions test\n",
    "- partie II\n",
    "    - Calcul du gradient d'une fonction de manière approchée (pour couvrir des cas où le calcul explicite du gradient est impossible ou pénible).\n",
    "- partie III\n",
    "    - La descente dans la direction du Gradient à pas constant\n",
    "    - Optimisation du pas par Backtracking\n",
    "- partie IV\n",
    "    - Choix d'une autre direction que le gradient\n",
    "        - De plus forte pente en norme $l_1$\n",
    "        - Gradient conjugué\n",
    "- partie V\n",
    "    - Accélération : Momentum, Nesterov, Adagrda.\n",
    "- partie VI\n",
    "    - La Méthode de Newton et la méthode de quasi-Newton\n",
    "\n",
    "    \n",
    "Dans l'ensemble du déroulé du TP vous ferez bien attention à valider par un jeu de tests la validité des programmes écrits. Vous regarderez l'influence des paramètres sur la convergence. Vous comparerez les intérêts des diférentes méthodes les unes par rapport aux autres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attendus de rendu\n",
    "\n",
    "Jusqu'il n'y a pas très longtemps (l'année dernière, pour être précis), les étudiants étaient évalués sur leur capacité à implémenter des méthodes de descentes opérationnelles et à les comparer entre elles.<br>\n",
    "Il est aujourd'hui très facile d'implémenter n'importe quel algorithme de descente, en n'importe quel langage (merci ChatGPT). Les attendus sont donc amenés à changer : exit la vérification que le code que vous avez écrit est correct (car il n'est plus possible d'en garantir la source (sachant que ça n'était déjà pas évident par le passé...)).\n",
    "\n",
    "Cependant, la capacité à produire un benchmark de qualité, et surtout à l'analyser de manière rigoureuse et d'en tirer des conclusions pertinentes, reste quand même propre à l'humain.\n",
    "\n",
    "**Votre rendu sera donc jugé sur** :\n",
    "- l'étude effectuée concernant la sensibilité de vos algorithmes de descente aux hyperparamètres / conditions initiales\n",
    "- l'analyse comparative proposée quant aux différentes implémentations suggérées \n",
    "- la précision et concision des résultats présentés (par exemple, dans les choix que vous ferez pour visualiser l'influence de tel ou tel paramètre sur telle ou telle métrique attestant de la convergence de votre algorithme).\n",
    "\n",
    "Comme vous allez le découvrir, ce TP est très riche et très long. Il n'est pas attendu de vous que vous implémentiez nécéssairement **toutes** les méthodes demandées, ni que vous benchmarkiez pour une méthode donnée, l'influence de **tous** les hyperparamètres. C'est à vous de choisir ce que vous voulez comparer, en fonction de ce qui a le plus éveillé votre curiosité lors des cours en lien avec les méthodes de descente.\n",
    "\n",
    "À titre d'exemple, voici le genre de *benchmarks* que vous pouvez faire en fonction de leur difficulté (symbolisée par le nombre de ⭐):\n",
    "- Influence du pas sur le nombre d'itérations dans le cas de la descente de gradient à pas constant et adéquation avec la théorie (⭐)\n",
    "- Influence d'un hyperparamètre du critère d'Armijo dans le cas d'une descente de gradient pour une fonction convexe (⭐)\n",
    "- Influence du critère d'arrêt sur le nombre d'itérations de la méthode de descente (⭐)\n",
    "- Influence conjointe des deux hyperparamètres du critère d'Armijo dans le cas d'une descente de gradient pour une fonction convexe (⭐⭐)\n",
    "- Influence du choix de la méthode (Fletcher-Reeves vs Polack-Ribière) pour l'algorithme du gradient conjugué pour une classe de fonction non-convexes (⭐⭐)\n",
    "- Comparaison de rapidité et de précision pour les méthodes de gradient conjugué, Newton (dans le cas quadratique) et quasi-Newton dans le cas général (⭐⭐⭐)\n",
    "\n",
    "Évidemment, libre à vous de conduire n'importe quel autre type de benchmark, du moment que votre choix est justifié.\n",
    "\n",
    "⚠️ Un benchmark bien conduit, c'est bien. Mais un benchmark bien conduit **et** bien analysé, c'est mieux ! Pour chaque benchmark que vous produirez, chaque courbe que vous tracerez, vous devez donc vous poser la question \"Que puis-je en déduire ? Est-ce conforme à ce que prédit la théorie (ou à minima, l'intuition que j'ai du fonctionnement de la méthode qui est benchmarkée) ?\n",
    "\n",
    "Ce TP est à rendre par **groupe de 2** ou **par groupe de 3**.<br>\n",
    "Dans tous les cas, vous devrez rendre un rapport au format pdf regroupant tous les benchmarks et analyses que vous voudrez présenter :\n",
    "- 10 $\\pm$ 1 pages si vous travaillez à 2\n",
    "- 15 $\\pm$ 1 pages si vous travaillez à 3\n",
    "\n",
    "Des pénalités s'appliqueront sur la notation pour tout rapport trop court ou trop long. **Dans tous les cas, vous indiquerez la répartition du travail au sein du groupe** (qui a réalisé quel benchmark, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Au travail!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I- Un set de fonctions tests\n",
    "\n",
    "Cette partie ne nécessite pas de travail de votre part\n",
    "\n",
    "Nous allons ici introduire quelques fonctions test qui permettent de représenter les situations suivantes:\n",
    "- Fonctions globalement convexes ou uniquement localement convexes\n",
    "- Fonctions admettant ou non un minimum global\n",
    "- Fonctions admettant ou non des minimums locaux\n",
    "\n",
    "Nous partons de fonctions définies sur $\\mathbb{R}$ mais on verra que cela permet de définir des fonctions \"intéressantes\" sur $\\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions du set de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Définir des familles de fonctions *convexes* sur $\\mathbb{R}$  ou sur une partie de $\\mathbb{R}$ ayant un nombre de conditionnement uniquement dépendant des paramètres de la famille.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic1_(x,gamma):\n",
    "    return gamma*(x**2) + x + 1 #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "x = np.linspace(-5, 5, 400)\n",
    "ax.set_ylim(-1, 100)\n",
    "for gamma in range(5, 50, 5):\n",
    "    ax.plot(x, quadratic1_(x, gamma), label=\"gamma: {}\".format(gamma))\n",
    "ax.set_title(\"Famille quadratiques en dimension 1\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic1_(x,gamma):\n",
    "    return x**3 + gamma*x**2 + x + 1 #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "x = np.linspace(-10, 10, 400)\n",
    "ax.set_ylim(-50, 150)\n",
    "for gamma in range(0, 11, 1):\n",
    "    ax.plot(x, cubic1_(x, gamma), label=\"gamma: {}\".format(gamma))\n",
    "ax.set_title(\"Famille cubique en dimension 1\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multitrous1_(x,gamma):\n",
    "        return 20*np.cos(x**2) + (gamma * x**2) #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 9))\n",
    "x = np.linspace(-10, 10, 400)\n",
    "ax.set_ylim(-100, 1000)\n",
    "for gamma in range(1, 11, 1):\n",
    "    ax.plot(x, multitrous1_(x, gamma), label=\"gamma: {}\".format(gamma))\n",
    "ax.set_title(\"Famille multi-puits en dimension 1\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Faire de même avec des fonctions sur $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic2_(x,gamma):\n",
    "        return quadratic1_(x[0],gamma[0])+quadratic1_(x[1],gamma[1]) #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -5, 5, -5, 5\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "gamma=np.zeros(2)\n",
    "gamma[0]=10\n",
    "gamma[1]=1\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=quadratic2_(np.array([X[i,j],Y[i,j]]),gamma)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "\n",
    "ax.contour(X, Y, Z,20) \n",
    "  \n",
    "ax.set_title('fonction quadratic2') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic2_(x,gamma=10):\n",
    "        return cubic1_(x[0],gamma)+cubic1_(x[1],gamma) #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -10, 5, -10, 5\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=cubic2_(np.array([X[i,j],Y[i,j]]))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "\n",
    "ax.contour(X, Y, Z,50) \n",
    "  \n",
    "ax.set_title('fonction cubic2') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multitrous2_(x,gamma=4):\n",
    "        return multitrous1_(x[0],1)+multitrous1_(x[1],gamma) #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -7.5, 7.5, -7.5, 7.5\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=multitrous2_(np.array([X[i,j],Y[i,j]]))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "\n",
    "ax.contour(X, Y, Z,50) \n",
    "  \n",
    "ax.set_title('fonction multitrou2') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. On construit ici une fonction convexe en dimension n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On va prendre comme fonction test la fonction convexe \"générique\" dans $\\mathbb{R}^n$, $ x \\mapsto \\frac{1}{2}x^T A x-b^Tx$, \n",
    "\n",
    "où A est une matrice symétrique définie positive de taille $(n,n)$ et $b$ un vecteur de $\\mathbb{R}^n$.\n",
    "\n",
    "On a vu en cours que cette fonction est convexe, qu'elle admet donc un minimum global sur $\\mathbb{R}^n$, et que ce minimum est atteint au point où son gradient s'annule, c'est à dire au point où $Ax=b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Une manière commode de construire une matrice $A$ symétrique définie positive est de la voir comme une matrice de la forme $A=U^T U$ avec $U$ triangulaire supérieure car cela nous permet  à la fois de s'assurer qu'elle est symétrique, inversible, positive et en plus de \"contrôler\" les valeurs propres de $A$ et donc son conditionnement.\n",
    "Le conditionnement de $A$ est le rapport entre la plus grande et la plus petite de ses valeurs propres. C'est le carré du rapport entre la plus grande et la plus petite des valeurs propres de $U$ qu'on trouve sur la diagonale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_system (dim,cond=10,seed=100):\n",
    "    np.random.seed(seed)\n",
    "    A=0.1*np.random.uniform(-math.sqrt(cond),math.sqrt(cond),size=(dim,dim))\n",
    "    A=np.triu(A)\n",
    "    # on remplace la diagonale de A par des valeurs aléatoires positives entre 1 et sqrt(cond)\n",
    "    A=A-np.diag(np.diag(A))+np.diag(np.random.uniform(1.,math.sqrt(cond),size=(dim))) \n",
    "    # on impose les deux premiers termes de la diagonale diagonale de A pour fixer le conditionnement\n",
    "    A[0,0]=1.\n",
    "    A[1,1]=math.sqrt(cond)\n",
    "    b=1.*np.random.randint(-10,10,size=(dim))\n",
    "    A=A.T @ A\n",
    "    return A,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A,b = create_system(5,cond=10)\n",
    "print (A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadraticn_(x):\n",
    "    return (x.T@A@x)/2-b.T@x #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -20, 10, -10, 10\n",
    "\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "dim=2\n",
    "A,b = create_system(dim,cond=10)\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=quadraticn_(np.array([X[i,j],Y[i,j]]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "\n",
    "ax.contour(X, Y, Z,15) \n",
    "  \n",
    "ax.set_title('quadraticn_') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. La banane de Rosenbrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Voici une fonction célèbre pour tester les algorithmes d'optimisation.\n",
    "\n",
    "$$f(x,y)=(x-1)^2+\\gamma (x^2-y)^2.$$\n",
    "\n",
    "Ce n'est pas évident à visualiser mais cette fonction présente un minimum global unique qui se situe au fond d'une vallée très étroite et en forme de parabole.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rosenbrock(x,gamma=100):\n",
    "        return (x[0]-1)**2+gamma*(x[0]**2-x[1])**2 #valeur de la fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -1, 1.5, -0.5, 2\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=Rosenbrock(np.array([X[i,j],Y[i,j]]))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) \n",
    "ax.contour(X, Y, Z,100) \n",
    "ax.set_title('fonction Rosenbrock') \n",
    "ax.set_xlabel('x') \n",
    "ax.set_ylabel('y') \n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "cmap='jet', edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On voit sur ces quelques exemples que des fonctions d'apparence \"inoffensives\" peuvent avoir des comportements complexes en ce qui concerne leurs extrema locaux ou globaux.\n",
    "\n",
    "${\\bf Nous \\, vous \\, invitons \\, à \\, tester}$ les programmes que vous écrirez:\n",
    "* sur la fonction quadratique pour la dimension n=2 puis n=10, et pour des conditionnements variant de 5 à 1000.\n",
    "* sur la fonction de Rosenbrock pour des valeurs de gamma variant de 5 à 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## II- Différencier une fonction numériquement\n",
    "\n",
    "On verra aussi comment calculer le gradient de manière approchée. Cela est particulièrement utile quand la seule information disponible sur la fonction à minimiser est sa valeur en tout point.\n",
    "\n",
    "Pour calculer le gradient d'une fonction on a déjà besoin de savoir calculer la dérivée d'une fonction réelle, et on en tire ensuite une version numérique du gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le calcul numérique de la dérivée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pour $h$ assez petit on peut approcher $f'(x)$ par \n",
    "$$ f'(x) \\simeq \\frac{f(x + h) - f(x)}{h} .$$\n",
    "L'erreur de l'approximation est en $o(1)$ quand $h \\to 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$ $$\n",
    "On peut en réalité faire un peu mieux en approchant $f'(x)$ par \n",
    "$$f'(x) \\simeq \\frac{f(x+h)-f(x-h)}{2h}.$$\n",
    "On trouve que l'erreur d'approximation dans le second cas est désormais en $o(h)$ quand $h \\to 0$; ce qui est a priori meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Utiliser la démarche précédente pour approcher la dérivée partielle d'une fonction en un point. Cette fonction sera notée `partial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial(f, x, i=0, dx=1e-8):\n",
    "    \"\"\"Computes i-th partial derivative of f at point x.\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which partial derivative is computed.\n",
    "        i: coordinate along which derivative is computed.\n",
    "        dx: slack for finite difference.\n",
    "        \n",
    "    Output:\n",
    "        (float)\n",
    "\n",
    "    \"\"\"\n",
    "    h = np.zeros(x.size)\n",
    "    h[i] = dx\n",
    "    return (f(x + h) - f(x - h)) / (2*dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Comparer `partial` à l'expression exacte de la dérivée partielle d'une fonction de votre choix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial(lambda x: np.exp(x), np.array([100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(np.array([100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le calcul du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dit précédemment, comme le calcul exact du gradient n'est parfois pas possible ou facile, on se garde la possibilité de calculer numériquement le gradient d'une fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Écrire une fonction `gradient` qui renvoie le gradient d'une fonction en un point grâce à la fonction précédente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(f, x, dx=1e-8):\n",
    "    \"\"\"Computes gradient of f at point x.\n",
    "    \n",
    "    Args:\n",
    "        f: objective function.\n",
    "        x: point at which gradient is computed.\n",
    "        dx: slack for finite difference of partial derivatives.\n",
    "        \n",
    "    Output:\n",
    "        (ndarray) of size domain of f.\n",
    "        \n",
    "    \"\"\"\n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tester cette fonction gradient sur une fonction connue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.zeros(2)\n",
    "x[0]=1\n",
    "x[1]=10\n",
    "gradient(lambda x: x[0]**5 + x[1]**2, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## III- Descente du gradient\n",
    "\n",
    "Tout d'abord, nous allons implémenter des descentes qui se feront dans la direction du Gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### le cas générique de descente de gradient avec un pas constant\n",
    "\n",
    "\n",
    "* prendre un point de départ au hasard ${\\bf x_0}$.\n",
    "\n",
    "Quand on est au point ${\\bf x_k}$\n",
    "\n",
    "* calculer le gradient de $f$ en ce point $\\nabla f({\\bf x_k})$\n",
    "\n",
    "* On choisit une direction de descente ${\\bf d}_k = - \\nabla f({\\bf x}_k)$\n",
    "\n",
    "* avancer dans cette direction : ${\\bf x}_{k+1} = {\\bf x}_k + \\eta \\, {\\bf d}_k$\n",
    "\n",
    "et on recommence cette dernière étape jusqu'à ce qu'on arrive à un point fixe c.a.d. que \n",
    "$|| {\\bf x}_{k+1} - {\\bf x}_k|| < \\varepsilon$ avec $\\varepsilon$ une toute petite valeur.\n",
    "\n",
    "Implémenter cette méthode, la tester sur des fonctions tests définies plus haute, observer en particulier le comportement en fonction de $\\mu$ qui est le pas constant.\n",
    "\n",
    "Attention: bien prévoir dans le code des conditions pour éviter de se retrouver piégé dans des boucles infinies !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Implémenter cette méthode, la tester sur des fonctions tests définies plus haute, observer en particulier le comportement en fonction de $\\eta$ qui est le pas constant.\n",
    "\n",
    "Attention: bien prévoir dans le code des conditions pour éviter de se retrouver piégé dans des boucles infinies !!!\n",
    "On conseille de stocker les différentes valeurs calculées pour les points ${\\bf x_k}$ afin de pouvoir \"regarder\" la manière dont la convergence se passe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_grad_const (f,x0,eta=0.001,eps=1E-6):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "    Parameters:\n",
    "    x0: point initial\n",
    "    f: fonction à minimiser\n",
    "    eta: valeur constante du pas (0.001 par défaut)\n",
    "    eps: critère à partir duquel on considèrera que la suite est \"constante\"\n",
    "    \n",
    "    Output\n",
    "    Tableau contenant l'ensemble des positions successives p_k\n",
    "    \"\"\"\n",
    "    \n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=10\n",
    "cond=100.\n",
    "A,b = create_system(dim,cond)\n",
    "x_exact=np.zeros(dim)+1.\n",
    "b=A@x_exact\n",
    "\n",
    "x0=np.zeros(dim)\n",
    "res = desc_grad_const(quadraticn_,x0,mu=0.01)\n",
    "\n",
    "print (\"Nb itérations\",len(res))\n",
    "print(\"x_calculé\",res[-1])\n",
    "print (\"x_exact\",x_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1ère amélioration: le choix d'un pas \"optimal\" à chaque étape par *backtracking* (ou rebroussement avec critère d'Armijo)\n",
    "\n",
    "Vous devriez avoir constaté que le choix du pas de descente dans le cas constant est crucial pour garantir la convergence de l'algorithme de descente. Dans cette section on s'intéresse à un calcul adaptatif du pas de descente qui permet de mieux garantir la convergence de notre algo. Le désavantage est le temps que prend désormais chaque itération pour s'exécuter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on veut imposer la décroissance de la suite $f({\\bf x}_k)$ ce qui nous assurera la convergence. Mais pour assurer la convergence vers un minimum, il faut imposer un peu plus que simplement de descendre, c'est ce que traduit le critère d'Armijo.\n",
    "\n",
    "On prend ici deux paramètres $0<\\alpha<0.5$ et $0<\\beta<1$.\n",
    "\n",
    "On cherche un $\\eta$ qui vérifie:\n",
    "$$ f({\\bf x}_k+\\eta {\\bf d}_k) < f({\\bf x}_k) + \\alpha \\, \\eta \\, {\\bf d}_k ^T \\, \\nabla f({\\bf x}_k)\\quad (1).$$\n",
    "\n",
    "Un tel $\\eta$ existe dès que ${\\bf d}_k$ est une direction de descente (c'est à dire dès que ${\\bf d}_k ^T \\, \\nabla f({\\bf x}_k) \\, <\\, 0$.\n",
    "\n",
    "* On part de $\\eta = 1$\n",
    "\n",
    "* si la condition $(1)$ ci-dessus est vérifiée on choisit cette valeur de $\\eta$\n",
    "\n",
    "* sinon on change $\\eta$ en $\\beta \\, \\eta$\n",
    "\n",
    "Et on recommence jusqu'à ce que la condition $(1)$ soit vérifiée.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Écrire une fonction `backtracking` qui permet de calculer le pas par *backtracking* avec critère d'Armijo à une itération donnée. Pour rappel le *backtracking* a deux hyper-paramètres $\\alpha$ et $\\beta$ que vous mettrez par défaut à $0.4$ et $0.8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fonction génère la taille du pas optimal vérifiant le critère d'Amijo\n",
    "\n",
    "def backtrack(x0, f , dir_x, alpha = 0.4, beta = 0.8):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "    Parameters:\n",
    "    x0: point actuel\n",
    "    f: fonction à minimiser\n",
    "    dir_x: direction dans laquelle on souhaite aller\n",
    "    \n",
    "    Output\n",
    "    valeur du pas optimal\n",
    "    \"\"\"\n",
    "    \n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode est donc très analogue à la précédente\n",
    "\n",
    "* prendre un point de départ au hasard ${\\bf x_0}$.\n",
    "\n",
    "Quand on est au point ${\\bf x_k}$\n",
    "\n",
    "* Calculer le gradient de $f$ en ce point $\\nabla f({\\bf x_k})$\n",
    "\n",
    "* Choisir une direction de descente ${\\bf d}_k = - \\nabla f({\\bf x}_k)$\n",
    "\n",
    "* Trouver $\\eta_k$ par \"backtracking\" dans la direction ${\\bf d}_k$\n",
    "\n",
    "* Avancer dans cette direction et avec ce pas : ${\\bf x}_{k+1} = {\\bf x}_k + \\eta \\, {\\bf d}_k$\n",
    "\n",
    "et on recommence ces étapes jusqu'à ce qu'on arrive à un point fixe c.a.d. que \n",
    "$|| {\\bf x}_{k+1} - {\\bf x}_k|| < \\varepsilon$ avec $\\varepsilon$ une toute petite valeur.\n",
    "\n",
    "#### 2. Implémenter cette méthode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_grad_opti (f,x0,eps=1E-6):\n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (quadratic_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (Rosenbrok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Comparer la descente par backtracking et la descente à pas constant (à vous de réfléchir à ce que vous voulez comparer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## IV- Changement de direction de descente\n",
    "\n",
    "Maintenant nous ne nous déplacerons plus nécessairement dans la direction de $-\\nabla f({\\bf x_k})$ mais dans une autre direction $d_k$ qui vérifiera bien évidemment $\\langle \\nabla f({\\bf x_k}) , d_k \\rangle < 0$ afin que ce soit bien une direction de descente (et non de montée !!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Choisir une direction de descente selon la plus forte pente en norme $l_1$\n",
    "\n",
    "Nous allons ici choisir la descente de plus forte pente dans le cas de la norme $\\ell_1$ : la direction de descente $d_k$ suit le vecteur de la base canonique de plus grande dérivée partielle en valeur absolue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {\\bf d}_k = -\\langle \\nabla f({\\bf x}_k),e_i \\rangle \\, e_i$$\n",
    "où $i$ est le plus petit indice tel que:\n",
    "$ \\left| \\dfrac{\\partial f}{\\partial x_i}({\\bf x}_k) \\right| = \\|\\nabla f({\\bf x}_k)\\|_{\\infty}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Écrire une fonction `dsgd` qui calcule cette direction de descente de plus forte pente dans le cas de la norme $\\ell_1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsgd(f, x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: \n",
    "    Parameters:\n",
    "    x: point actuel\n",
    "    f: fonction à minimiser\n",
    "    \n",
    "    Output\n",
    "    vecteur de direction de descente de gradient maximal en norme l1\n",
    "    \"\"\"\n",
    "    \n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Ecrire la descente à pas optimal avec cette direction de descente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\bf x}_{k+1} = {\\bf x}_k + \\eta_k {\\bf d}_k$, où $\\mu_k$ est calculé de manière optimale par l'algorithme de rebroussement avec critère d'Amijo défini plus haut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_l1_opti (f, x0, eps=1E-6):\n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (quadratic_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (Rosenbrok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Comparer la descente $\\ell_1$ et la descente du gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. le gradient conjugué (Fletcher-Reeves)\n",
    "\n",
    "Dans la méthode du gradient conjugué, on modifie la direction de descente en ajoutant à l'opposé du gradient un terme dépendant des directions de descente précédentes. Ce choix de descente est fait pour rendre deux directions de descentes orthogonales pour le produit scalaire qui vient de la Hessienne.\n",
    "\n",
    "Ce calcul (qui est direct quand la fonctionnelle est quadratique) peut devenir compliqué quand la Hessienne n'est pas directement accessible.\n",
    "\n",
    "Une des méthodes les plus populaires pour une fonctionnelle quelconque est celle proposée par Fletcher-Reeves. Nous vous invitons à faire un peu de bibliographie pour trouver comment la direction est choisie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Ecrire la descente à pas optimal avec cette direction de descente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_FR_opti (f, x0, eps=1E-6):\n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (quadratic_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (Rosenbrok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. le gradient conjugué (Polack-Ribière)\n",
    "\n",
    "Une méthode alternative est celle proposée par Polack-Ribière. À noter qu'elle est (théoriquement) équivalente à la méthode de Fletcher-Reeves lorsque la fonctionnelle à minimiser est quadratique, mais sensiblement plus efficace dans le cas général (non quadratique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Ecrire la descente à pas optimal avec cette direction de descente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_PR_opti (f, x0, eps=1E-6):\n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (quadratic_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (Rosenbrok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. visualiser une comparaison des différents algorithmes de descente et leur sensibilité par rapport au conditionnement\n",
    "\n",
    "Nous vous proposons de visualiser le comportement de ces différents algorithmes de descente.\n",
    "\n",
    "Tout d'abord en dimension 2, vous pouvez tracer la succession des points $x_k$ pour les algorithmes implémentés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=2\n",
    "A,b = create_system(dim,cond=3.)\n",
    "x_exact=np.zeros(dim)+1.\n",
    "b=A@x_exact\n",
    "\n",
    "x0=np.zeros(dim)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "Liste_method=(desc_grad_const,desc_grad_opti,desc_l1_opti,desc_FR_opti,desc_PR_opti)\n",
    "\n",
    "for method in Liste_method:\n",
    "\n",
    "    if method == desc_grad_const:\n",
    "        res = method(quadraticn_,x0,eta=0.9/cond)\n",
    "    else:\n",
    "        res = method(quadraticn_,x0)\n",
    "\n",
    "    plt.plot(res[:,0], res[:,1],label=method)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "nb_pts, x_mi, x_ma, y_mi, y_ma = 200, -0.1, 1.1, -0.1, 1.3\n",
    "\n",
    "x, y = np.linspace(x_mi, x_ma, nb_pts), np.linspace(y_mi, y_ma, nb_pts)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z=np.zeros((nb_pts,nb_pts))\n",
    "\n",
    "for i in range (nb_pts):\n",
    "    for j in range (nb_pts):\n",
    "        Z[i,j]=quadraticn_(np.array([X[i,j],Y[i,j]]))\n",
    "        \n",
    "        \n",
    "plt.contour(X, Y, Z,25) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En dimension n plus grande (par exemple n=10), vous pourrez tracer le nombre d'itérations nécessaires pour converger en fonction du conditionnement (5,10,50,100,500,1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez aussi regarder pour une certaine valeur de conditionnement, comment varie la distance à la solution exacte en fonction de l'itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. comportement si la fonction à optimiser n'est pas convexe sur $\\mathbb{R}^2$ et n'admet pas un minimum global\n",
    "\n",
    "Nous vous proposons de regarder le comportement de ces différents algorithmes de descente dans le cas de quelques fonctions introduites au début du TP, telles que multitrous2, cubic2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (multitrous2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (cubic2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que constatez-vous ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V Accélérations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a des stratégies standards d'accélération de descente de gradients ; on en invente même tous les ans. Il n'y a pas nécessairement de relation d'ordre entre celles-ci, certaines sont plus adaptées que d'autres à des problèmes spécifiques et inversement. On vous propose d'implémenter 3 méthodes \"simples\" : *momentum*, *Nesterov* et *Adagrad* (*Adaptive gradient*). Contrairement aux deux premières pour lesquelles le pas reste fixe en fonction des variables à optimiser, *Adagrad* adapte le pas d'une variable à l'autre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implémenter la *Momentum Optimisation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implémenter la *Nesterov Optimisation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implémenter la *Adagrad Optimisation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Comparer l'accélération choisie avec les méthodes précédentes précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI - \"Les\" méthodes de Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. la méthode de Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les méthodes de descente précédentes, on cherchait à chaque étape à minimiser le Développement Limité d'ordre 1 de J au voisinage de ${\\bf x_k}$: $h \\mapsto f({\\bf x_k}) + \\nabla f({\\bf x_k}) ^T h$.\n",
    "\n",
    "Dans la méthode de Newton, on cherche à minimiser le Développement Limité d'ordre 2 de J au voisinage de ${\\bf x}_k$ : $h \\mapsto f({\\bf x}_k) + \\nabla f({\\bf x}_k) ^T h + \\dfrac{1}{2}h^T H_f({\\bf x}_k) h$ où $H_f({\\bf x}_k)$ est la Hessienne de $f$ au point ${\\bf x}_k$.\n",
    "\n",
    "A quelle direction de descente, cette minimisation nous amène-t-elle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réponse:\n",
    "\n",
    "\n",
    "On passe de la direction ${\\bf d}_k$ à la direction ${\\bf d}_{k+1}$ par la relation de récurrence:\n",
    "$${\\bf d}_{k+1}=-H_f({\\bf x}_k)^{-1} \\, \\nabla f({\\bf x}_k) .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Implémenter la méthode de Newton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En apparence, implémenter la méthode de Newton (qui converge très rapidement) ne semble pas différent que les méthodes de descente vues précédemment\n",
    "\n",
    "En réalité cette méthode n'est pas facile à implémenter et surtout coûteuse car il faut calculer à chaque itération la Hessienne de $f$ au point ${\\bf x}_k)$ et ensuite l'inverser.\n",
    "\n",
    "Vous pouvez essayer de l'implémenter dans le cas particulier de la fonction quadraticn_ car alors la matrice Hessienne est constante et ne dépend donc pas du point ${\\bf x}_k)$, ce qui vous permet de calculer une fois pour toute son inverse (par le module linalg de numpy par exemple).\n",
    "\n",
    "Par contre implémenter cette méthode dans le cas d'une fonction dont on ne connaît pas explicitement la Hessienne, et surtout l'inverse de cette dernière est à déconseiller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. la méthode de quasi-Newton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter les inconvénients de la méthode de Newton, en particulier lorsque la Hessienne n'est plus constante, une idée est d'introduire une suite de matrices $H_k$ qui sont une approximation de $\\bf {l'inverse}$ de la Hessienne au point ${\\bf x}_k$.\n",
    "\n",
    "Cette méthode qui s'appelle méthode BFGS (des initiales des auteurs qui l'ont introduite), a l'avantage (énorme) de ne pas nécessiter le calcul de la Hessienne ou de son inverse. on retrouve donc en terme d'implémentation la simplicité des méthodes de descente, tout en ayant les propriétés de convergence de la méthode de Newton.\n",
    "\n",
    "L'algorithme le décrivant est le suivant (très analogue aux algorithmes de descente):\n",
    "\n",
    "* prendre un point de départ quelconque ${\\bf x}_0$\n",
    "* prendre une matrice $H_0$ quelconque, par exemple $H_0= I_n$ \n",
    "\n",
    "Quand on est au point ${\\bf x}_k$\n",
    "\n",
    "* Choisir une direction de descente ${\\bf d}_k = -H_k \\, \\nabla f({\\bf x}_k)$\n",
    "\n",
    "* Trouver $\\eta_k$ par \"backtracking\" dans la direction ${\\bf d}_k$\n",
    "\n",
    "* Avancer dans cette direction et avec ce pas : ${\\bf x}_{k+1} = {\\bf x}_k + \\eta_k \\, {\\bf d}_k$\n",
    "\n",
    "* Calculer $H_{k+1}$ en fonction de $H_{k+1}$, $f({\\bf x}_k)$, $f({\\bf x}_{k+1})$, $\\nabla f({\\bf x}_k)$ et $\\nabla f({\\bf x}_{k+1})$.\n",
    "\n",
    "et on recommence ces étapes jusqu'à ce qu'on arrive à un point fixe c.a.d. que \n",
    "$|| {\\bf x}_{k+1} - {\\bf x}_k|| < \\varepsilon$ avec $\\varepsilon$ une toute petite valeur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La formule qui donne la suite des matrices $H_{k}$ semble à première vue horrible. Mais elle se programme en Python en 1 ligne en ne faisant que des multiplications de matrices et de vecteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Implémenter la méthode de Quasi-Newton BFGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_BFGS_opti (f, x0, eps=1E-6):\n",
    "    # 👷 À VOUS DE JOUER 👷\n",
    "    # return xk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tester cette descente sur un cas simple (prendre par exemple en dimension n=10, la fonction quadraticn_ dans un cas où vous connaissez la solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (quadratic_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (Rosenbrok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷 (cubic2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Comparer la méthode de quasi-Newton aux descentes précédentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👷 À VOUS DE JOUER 👷"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
